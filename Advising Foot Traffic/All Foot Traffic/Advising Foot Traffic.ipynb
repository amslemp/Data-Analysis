{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advising Foot Traffic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algo works through all the foot traffic data at each of the locations. From this data, we can clearly see how many students are calling, emailing, or walking into the office throughout the year. This data is cleaned here in python before moving over to a PowerBI report. It is not necessary to have it in real-time streaming data as the Director and VP cannot even attend to it that frequently. Therefore, this is batched monthly and upon request if it needs to be more frequent.\n",
    "\n",
    "<div class=\"alert\" style=\"background-color:#ffa590;\"><strong>Note:</strong> \n",
    "Before you download the CSVs, you need to convert all of the *date* columns to MM/DD/YY. This will allow the to_datetime() method to be properly applied.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Path to code folder\n",
    "CODE_FOLDER = Path('code')\n",
    "CODE_FOLDER.mkdir(exist_ok=True)\n",
    "sys.path.extend([f\"./{CODE_FOLDER}\"])\n",
    "\n",
    "# Path to data\n",
    "DATA_PATH = Path.cwd()/'Data'\n",
    "\n",
    "# Path to saved files\n",
    "COMBINED_LOCATIONS = 'Files/mashup.csv'\n",
    "DASHBOARD_SETUP = 'Files/Dashboard Setup.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The section below is the new code for the new dashboard setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import retrieve_and_open_csv_files\n",
    "from processing import new_dashboard_cleaned_dates, dashboard_setup\n",
    "\n",
    "#Start setting up the dashboard with the new sign-in sheet setup. (1.26.22)\n",
    "dash = retrieve_and_open_csv_files(DATA_PATH, keyword='Advising')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dates, set up unique ID, clean up location data\n",
    "dash = new_dashboard_cleaned_dates(dash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup 'Type of Student' column\n",
    "stype = dashboard_setup(dash, ['CURRENT STUDENT', 'NEW STUDENT',\n",
    "                               'RETURNING STUDENT', \n",
    "                               'WORKFORCE', 'VETERAN', 'ATHLETE'], 'Type of Student')\n",
    "\n",
    "reason = dashboard_setup(dash, ['ENROLL', 'ADD/DROP', 'QUESTIONS', 'MAJOR CHANGE', 'DEGREE CHECK'], 'Reason For Visit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add new columns to the dataframe\n",
    "dash['TYPE OF STUDENT'], dash['REASON FOR VISIT'] = stype, reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alter HIGH SCHOOL column x's to 'HIGH SCHOOL' because the program we \n",
    "#wrote above was creating duplicates. This is because the student workers,\n",
    "#advising staff, and front office manager vary on when they mark a student \n",
    "#only as high school and mark a student as \"current\" or \"new\" *and* \n",
    "#high school. This was causing the original program to create duplicate \n",
    "#indeces. So in order to track both 'current' and 'high school' attributes,\n",
    "#I created this column.\n",
    "dash['MOD HIGH SCHOOL'] =  ['HIGH SCHOOL' if i == 'x' or i == 'X' else '' for i in dash['HIGH SCHOOL']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just as we did above for the mashup, we need to create columns for month\n",
    "#and day. Below is that process.\n",
    "month_dict = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6:'Jun', \\\n",
    "              7:'Jul', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
    "\n",
    "#Comprehension for Month\n",
    "mon = [month_dict.get(i) for i in list(dash['DATE'].dt.month)]\n",
    "\n",
    "#Create dictionary for days of the week\n",
    "day_of_week = {0: 'Mon', 1:'Tues', 2:'Wed', 3:'Thur', 4:'Fri', 5:'Sat', 6:'Sun'}\n",
    "\n",
    "#Comprehension for Days\n",
    "dow = [day_of_week.get(i) for i in list(dash['DATE'].dt.weekday)]\n",
    "\n",
    "#Combine new columns with old dash df\n",
    "dash['MONTH'], dash['DAY'] = mon, dow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display \n",
    "\n",
    "final_dash = dash[['ID', 'DATE', 'NAME', 'TIME RANGE', 'MONTH', 'DAY', 'LOCATION',\n",
    "                   'APPT', 'DISTANCE', 'TYPE OF STUDENT', 'REASON FOR VISIT', \n",
    "                   'MOD HIGH SCHOOL', 'ADVISOR SIGN', 'ADV TIME']]\n",
    "\n",
    "#The final setup was to create a column that helps us filter advisors by \n",
    "#the employment type (i.e. 'EMP TYPE')\n",
    "sign = {'KL':'28hr', 'KZ':'28hr', 'CJ':'40hr', 'SLB':'28hr','SV':'28hr',\n",
    "         'BG':'40hr', 'AKP':'28hr', 'JW':'40hr', 'AS':'40hr', 'SP':'40hr',\n",
    "         'SB':'20hr', 'DS':'Boss', 'AP':'40hr', 'SS': 'Not Sure', 'MZ':'Adm',\n",
    "         'JD':'Adm', 'MP':'Adm', 'BM':'40hr', 'CS':'Not Sure', 'RM':'40hr',\n",
    "         'SH':'40hr', 'KLA':'28hr', 'GR':'Adj', 'DR':'40hr', 'TB':'28hr', \n",
    "         'JEC':'28hr', 'KB':'28hr', 'KA':'28hr', '':'N/A'}\n",
    "\n",
    "#Since there are times the cell is left blank, pandas records that as a float\n",
    "#variable, which throws and error when doing a comprehension. Therefore, the \n",
    "#code below deals with that problem by filling all of the NaNs with a blank\n",
    "#string.\n",
    "final_dash['ADVISOR SIGN'] = final_dash['ADVISOR SIGN'].fillna('')\n",
    "\n",
    "s = [i.upper() for i in final_dash['ADVISOR SIGN']]\n",
    "\n",
    "final_dash['ADVISOR SIGN'] = s\n",
    "\n",
    "#Link dictionary we created to the advisor signatures and create new \n",
    "#columns with this new attribute\n",
    "s2 = [sign.get(i) for i in final_dash['ADVISOR SIGN']]\n",
    "\n",
    "final_dash['Emp Type'] = s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export dashbaord to csv\n",
    "dashboard = final_dash.to_csv(DASHBOARD_SETUP, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Deprecated` The Code Below Is For The Old Dashboard Setup\n",
    "\n",
    "In the first iteration of the sign in sheets, each site had some amount of freedom in how they used the sign in sheet and what they included in it. The new version standardized the column headings, order, and how they are used (in theory). I say in theory because humans inevitably enter data with different intentions and sometimes with different markings. One of the challenges in the office is that student workers come and go frequently, which means training and standards are difficult to maintain. I am not the trainer of new staff. This falls on the Office Manager. Only in extreme circumstances do I intervene to instruct new staff about the sign in sheet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from processing import (\n",
    "    modify_df, \n",
    "    create_dataframe, \n",
    "    clean_location_data, \n",
    "    dashboard_setup\n",
    ")\n",
    "\n",
    "boa = retrieve_and_open_csv_files(DATA_PATH, keyword = 'BOA')\n",
    "boe = retrieve_and_open_csv_files(DATA_PATH, keyword = 'BOE')\n",
    "bsc = retrieve_and_open_csv_files(DATA_PATH, keyword = 'BSC')\n",
    "bom = retrieve_and_open_csv_files(DATA_PATH, keyword = 'BOM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Apply the program to each of the sign-in sheets. \n",
    "boa2 = modify_df(boa, \"BOA\")\n",
    "boe2 = modify_df(boe, \"BOE\")\n",
    "bsc2 = modify_df(bsc, \"BSC\")\n",
    "bom2 = modify_df(bom, \"BOM\")\n",
    "\n",
    "# Combine locations\n",
    "all_locations = (pd.concat([boa2, boe2, bsc2, bom2])\n",
    "                   .reset_index(drop = True)\n",
    "                )\n",
    "\n",
    "# Clean data\n",
    "all_locations = clean_location_data(all_locations, COMBINED_LOCATIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number Seen by Each Advisor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataframe(all_locations, \"ADVISOR SIGN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distance Students Seen and in What Modality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = create_dataframe(all_locations, \"DISTANCE\")\n",
    "\n",
    "ls = []\n",
    "\n",
    "for i in list(distance['DISTANCE']):\n",
    "    if i not in ['Phone', 'Email', 'Central Adv']:\n",
    "        ls.append('Appt or In-Person')\n",
    "    else:\n",
    "        ls.append(i)\n",
    "\n",
    "distance['DISTANCE'] = ls\n",
    "\n",
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Appointment Type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appt = create_dataframe(all_locations, 'APPT')\n",
    "\n",
    "ap = []\n",
    "\n",
    "for i in list(appt['APPT']):\n",
    "    if i in ['Phone', 'Zoom', 'In Person']:\n",
    "        ap.append(i)\n",
    "    else:\n",
    "        ap.append('Walk In')\n",
    "\n",
    "appt['APPT'] = ap\n",
    "\n",
    "appt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data by Site: How Many Students Assisted by Location**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataframe(all_locations, \"LOCATION\")\n",
    "\n",
    "mask1 = all_locations['LOCATION'].isin(['BSC', 'BOM'])\n",
    "\n",
    "appt_types = all_locations[mask1].reset_index()\n",
    "\n",
    "pd.DataFrame(appt_types.groupby('DISTANCE')['index'].count())\\\n",
    "  .reset_index()\\\n",
    "  .rename(columns = {'index':'Num Of Students'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Day of Week Students Arrive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow = create_dataframe(all_locations, 'DAY')\n",
    "day_of_week = {'Mon':0 , 'Tues':1, 'Wed':2, 'Thur':3, 'Fri':4, 'Sat':5, 'Sun':6}\n",
    "filt = [day_of_week.get(i) for i in dow['DAY']]\n",
    "dow['FILTER'] = filt\n",
    "dow = dow.sort_values('FILTER').drop('FILTER', axis = 1).reset_index(drop = True)\n",
    "dow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
